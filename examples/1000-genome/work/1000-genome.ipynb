{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the 1000-genome workflow interactively on Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To investigate *Jupyter-Workflow* strong scalability on a distribured infrastructure, we execute an 8-chromosomes instance of the [1000-genome workflow](https://github.com/pegasus-isi/1000genome-workflow) on up to 500 concurrent Kubernetes Pods. We selected the 1000-genome workflow for three main reasons:\n",
    "* Pegasus is a state-of-the-art representative of HPC-oriented WMSs supporting execution environments without shared data spaces (via HTCondor);\n",
    "* The host code of each step is written in either Bash or Python, both supported by the standard IPython kernel;\n",
    "* The critical portion of the workflow id a highly-parallel step, composed of 2000 independent short tasks (~120s each on our infrastructure), which are critical for batch workload managers, but that can be executed at scale on on-demand Cloud resources (e.g. Kubernetes)\n",
    "\n",
    "In order to replicate the experiment, you need a Kubernetes cluster with 3 control plane VMs (4 cores, 8GB RAM each) and 16 large worker VMs (40 cores, 120GB RAM each). In our infrastructure, each Kubernetes worker node has been manually placed on top of a different physical node, managed by an OpenStack Cloud controller. Nodes were interconnected by a 10Gbps Ethernet.\n",
    "\n",
    "Each Pod requests 1 core and 2GB RAM and mounts a 1GB tmpfs under the `/tmp/streamflow` path, in order to avoid I/O bottlenecks. The description of such deployment is described in the `helm-1000-genome` model, which is managed by the StreamFlow Helm connector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial inputs of the workflow are listed in this cell. Please note that, before launching the pipeline, you need to download all the input data. This can be easily done through the provided `data/download_data.sh` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "chromosomes=[1, 2, 3, 4, 5, 6, 7, 8]\n",
    "individuals=sorted(glob.glob(\"data/20130502/*.vcf.gz\"))\n",
    "annotations=sorted(glob.glob(\"data/20130502/sifting/*\"))\n",
    "populations = sorted(glob.glob(\"data/populations/*\"))\n",
    "columns = \"data/20130502/columns.txt\"\n",
    "step = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the original Pegasus implementation, a chromosome input file is made available to all the workers involved in the *individuals* step in its entirety, and each of them selects a different partition to compute. Conversly, our implementation splits the dataset locally and then scatters it to the worker, transferring to each Pod only the strictly required amount of data.\n",
    "\n",
    "This configuration is necessary to reach a decent level of performance in a distributed infrastructure, where the workers do not share a common data space. The original strategy would instead generate an unsustainable load on the communication infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "workflow": {
     "step": {
      "in": [
       {
        "type": "file",
        "valueFrom": "individuals"
       }
      ],
      "out": [
       {
        "name": "individuals",
        "type": "file",
        "value": "ALL.chr*.250000.vcf.*"
       }
      ],
      "scatter": {
       "items": [
        "individuals",
        "chromosomes"
       ],
       "method": "dotproduct"
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$individuals\" \"$step\" \"$chromosomes\"\n",
    "\n",
    "inputfiles=($(echo $1 | tr -d \"[],'\"))\n",
    "step=\"${2}\"\n",
    "chromosomes=($(echo $3 | tr -d \"[],'\"))\n",
    "\n",
    "for i in ${!inputfiles[@]}; do\n",
    "    inputfile=${inputfiles[i]}\n",
    "    unzipped=\"${inputfile%.*z}\"\n",
    "    gunzip $inputfile\n",
    "\n",
    "    split --lines \"$step\" --suffix-length 3 -d $unzipped ./\"${unzipped##*/}.${chromosomes[i]}.\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this step is to fetch and parse the Phase3 data from the 1000 genomes project by chromosome. These files list all of Single nucleotide polymorphisms (SNPs) variants in that chromosome and which individuals have each one. SNPs are the most common type of genetic variation among people, and are the ones we consider in this work. An individual task creates output files for each individual of rs numbers 3, where individuals have mutations on both alleles.\n",
    "\n",
    "The first step, called *individuals*, is by far the heaviest in the workflow in terms of required computing time. Fortunately, it is also highly parallelizable. Indeed, each chromosome can be processed in parallel. Plus, each chromosome file is split in 250 chunks, for a total of 2000 independent tasks. Each task is then offloaded to one of the (up to 500) Pods in the `helm-1000-genome` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "stime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "workflow": {
     "step": {
      "in": [
       {
        "type": "file",
        "valueFrom": "individuals"
       },
       {
        "type": "file",
        "valueFrom": "columns"
       }
      ],
      "out": [
       {
        "name": "slices",
        "type": "file",
        "value": "chr*.tar.gz"
       }
      ],
      "scatter": {
       "items": [
        "individuals"
       ]
      }
     },
     "target": {
      "model": "helm-1000-genome",
      "service": "1000-genome"
     }
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$individuals\" \"$columns\"\n",
    "\n",
    "inputfiles=($(echo $1 | tr -d \"[],'\"))\n",
    "columfile=\"${2}\"\n",
    "\n",
    "for inputfile in ${inputfiles[*]}; do\n",
    "    start=`date +%s.%N`\n",
    "    basename=\"${inputfile##*/}\"\n",
    "    extension=\"${basename##*.}\"\n",
    "    nameroot=\"${basename%.*}\"\n",
    "    chromosome=\"${nameroot##*.}\"\n",
    "    outputfile=\"chr${chromosome}n-${extension}.tar.gz\"\n",
    "        \n",
    "    pdir=\"chr${chromosome}p/\"\n",
    "    ndir=\"chr${chromosome}n/\"\n",
    "    mkdir -p \"${pdir}\" \"${ndir}\"\n",
    "    \n",
    "    \n",
    "    if [ -s \"${inputfile}\" ]; then\n",
    "        awk -v c=${chromosome} '{for(i=10;i<=2513;i++) {name=\"chr\"c\"p/chr\"c\".p\"i-9;print $i\"   \"$2\"    \"$3\"    \"$4\"    \"$5\"    \"$8 >> name}}' ${inputfile}\n",
    "\n",
    "        for i in {1..2504}; do\n",
    "          col=$(($i + 9))\n",
    "          name=$(cut -f ${col} ${columfile})\n",
    "          oldfile=\"${pdir}chr${chromosome}.p${i}\"\n",
    "          newfile=\"${ndir}chr${chromosome}.${name}\"\n",
    "          cat ${oldfile} | awk '{print $6}' | awk -F \";\" '{print $9}'| awk -F\"=\" '{print $2}' > \"AF_value.${chromosome}\"\n",
    "          paste ${oldfile} AF_value.${chromosome} | awk '{$6=\"\"; print}'> \"tmp.file.${chromosome}\"\n",
    "          cat \"tmp.file.${chromosome}\" | awk ' $6 >= 0.5 {print $0}'| awk -F \"|\" '$1==0 || $2==0 {print $2}' > \"tmp.select.${chromosome}\"\n",
    "          cat \"tmp.file.${chromosome}\" | awk ' $6 < 0.5 {print $0}'| awk -F \"|\" '$1==1 || $2==1 {print $2}' >> \"tmp.select.${chromosome}\"\n",
    "          cat \"tmp.select.${chromosome}\" | awk '{print $2\"        \"$3\"    \"$4\"    \"$5\"    \"$6}' >> \"${newfile}\"\n",
    "          rm ${oldfile}\n",
    "        done\n",
    "\n",
    "        rm \"tmp.file.${chromosome}\"\n",
    "        rm \"tmp.select.${chromosome}\"\n",
    "        rm \"AF_value.${chromosome}\"\n",
    "    \n",
    "        tar -czf \"${outputfile}\" -C \"${ndir}\" .\n",
    "    else\n",
    "        tar -czf \"${outputfile}\" -T \"/dev/null\"\n",
    "    fi\n",
    "\n",
    "    rm -rf \"${ndir}\"\n",
    "    rm -rf \"${pdir}\"\n",
    "    end=`date +%s.%N`\n",
    "    echo \"$(echo \"$end $start\" | awk '{print $1 - $2}')\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130.1189863681793\n"
     ]
    }
   ],
   "source": [
    "etime = time.time()\n",
    "print(etime-stime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each chromosome file is split in chunks to be processed in parallel by the previous step. Then, the results produced for each chunk of a chromosome must be merged (i.e. concatenated). Different chromosomes can still be processed in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import posixpath\n",
    "slices = list({k: [v for v in slices if posixpath.basename(v).startswith(k)] for k in ['chr{c}n'.format(c=c) for c in chromosomes]}.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "workflow": {
     "step": {
      "in": [
       {
        "type": "file",
        "valueFrom": "slices"
       }
      ],
      "out": [
       {
        "name": "merged",
        "type": "file",
        "value": "chr*.tar.gz"
       }
      ],
      "scatter": {
       "items": [
        "slices"
       ]
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$slices\"\n",
    "\n",
    "start=`date +%s.%N`\n",
    "slices=($(echo $1 | tr -d \"[],'\"))\n",
    "\n",
    "for slice in ${slices[*]}; do\n",
    "  echo \"Merging ${slice}...\"\n",
    "  basename=${slice##*/}\n",
    "  chromosome=${basename%-*}\n",
    "  mkdir -p \"merged-${chromosome}\"\n",
    "  mkdir -p tmp\n",
    "  tar -xzf \"${slice}\" -C tmp\n",
    "  if [ \"$(ls -A tmp/)\" ]; then\n",
    "      for f in tmp/*; do\n",
    "        cat \"${f}\" >> \"merged-${chromosome}/${f##*/}\"\n",
    "      done\n",
    "  fi\n",
    "  rm -rf tmp\n",
    "done\n",
    "\n",
    "merged_folders=($(find . -name \"merged-*\"))\n",
    "\n",
    "for merged_folder in ${merged_folders[*]}; do\n",
    "    basename=\"${merged_folder##*/}\"\n",
    "    chromosome=\"${basename##*-}\"\n",
    "    outputfile=\"${chromosome}.tar.gz\"\n",
    "    echo \"Creating merged file ${outputfile}...\"\n",
    "    tar -czf \"${outputfile}\" -C \"${merged_folder}\" .\n",
    "    rm -rf \"${merged_folder}\"\n",
    "done\n",
    "\n",
    "end=`date +%s.%N`\n",
    "echo \"$(echo \"$end $start\" | awk '{print $1 - $2}')\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *sifting* task computes the SIFT scores of all of the SNPs variants, as computed by the Variant Effect Predictor (VEP). SIFT is a sequence homology-based tool that Sorts Intolerant From Tolerant amino acid substitutions, and predicts whether an amino acid substitution in a protein will have a phenotypic effect.\n",
    "\n",
    "For each chromosome the sifting task processes the corresponding VEP, and selects only the SNPs variants that has a SIFT score, recording in a file (per chromosome) the SIFT score and the SNPs variants ids, which are: (1) rs number, (2) ENSEMBL GEN ID, and (3) HGNC ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "workflow": {
     "step": {
      "in": [
       {
        "type": "file",
        "valueFrom": "annotations"
       }
      ],
      "out": [
       {
        "name": "sift",
        "type": "file",
        "value": "sifted.SIFT.chr*.txt"
       }
      ],
      "scatter": {
       "items": [
        "annotations",
        "chromosomes"
       ],
       "method": "dotproduct"
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$annotations\" \"$chromosomes\"\n",
    "\n",
    "inputfiles=($(echo $1 | tr -d \"[],'\"))\n",
    "chromosomes=($(echo $2 | tr -d \"[],'\"))\n",
    "\n",
    "for i in ${!inputfiles[@]}; do\n",
    "    inputfile=\"${inputfiles[i]}\"\n",
    "    siftfile=\"ALL.chr'${chromosomes[i]}'.vcf.gz\"\n",
    "    unzipped=\"${inputfile%.*z}\"\n",
    "    gunzip \"${inputfile}\"\n",
    "    header=$(head -n 1000 \"${unzipped}\" | grep \"#\" | wc -l)\n",
    "\n",
    "    echo \"taking columns from ${inputfile}\"\n",
    "    grep -n \"deleterious\\|tolerated\" \"${unzipped}\" | grep \"rs\" > ${siftfile}\n",
    "\n",
    "    lines='line.txt'\n",
    "    ids='id.txt'\n",
    "    info='info.txt'\n",
    "    sifts='sift.txt'\n",
    "\n",
    "    awk '{print $1}' ${siftfile} | awk -F \":\" '{print $1-'${header}'}' > \"${lines}\"\n",
    "    awk '{print $3}' ${siftfile} > ${ids}\n",
    "    awk '{print $8}' ${siftfile} > ${info}\n",
    "    awk -F \"|\" '{print $5\"\\t\"$17\"\\t\"$18}' \"${info}\" | sed 's/(/\\t/g' | sed 's/)//g' > \"${sifts}\"\n",
    "\n",
    "    final=\"sifted.SIFT.chr${chromosomes[i]}.txt\"\n",
    "    pr -m -t -s\\ \"${lines}\" \"${ids}\" \"${sifts}\" | gawk '{print $1,$2,$3,$5,$7}' > \"${final}\"\n",
    "\n",
    "    echo \"line, id, ENSG id, SIFT, and phenotype printed to ${final}\"\n",
    "\n",
    "    rm \"$siftfile\" \"$lines\" \"$ids\" \"$info\" \"$sifts\" \"$unzipped\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells define some common Python code (imports and classes) that will be used by the last two steps of the workflow.\n",
    "\n",
    "In the original setting there is a lot of duplicated code, due to the fact that each Python script must be self-contained, in order to be independently executed as an external command. Here we exploit the higher flexibility offered by the Jupyter Notebooks to refactor the code, removing duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from random import sample\n",
    "import os\n",
    "import os.path\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.pyplot import pcolor, show, colorbar, xticks, yticks\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import itertools\n",
    "import argparse\n",
    "#import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "import matplotlib as mpl\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "SIFT = 'NO-SIFT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadData :\n",
    "    def read_names(self, POP, columns) :\n",
    "        print('reading inidviduals')\n",
    "        f = open(POP, 'r')\n",
    "        text = f.read()\n",
    "        f.close()\n",
    "        text = text.split()\n",
    "        all_ids = text[0:]\n",
    "        file = columns\n",
    "        f = open(file, 'r')\n",
    "        text = f.read()\n",
    "        f.close()\n",
    "        genome_ids = text.split()\n",
    "        ids = list(set(all_ids) & set(genome_ids))\n",
    "        return ids\n",
    "    \n",
    "    def read_rs_numbers(self, siftfile) :\n",
    "        print('reading in rs with sift scores below %s' % SIFT)\n",
    "        rs_numbers = []\n",
    "        variations = {}\n",
    "        map_variations = {}\n",
    "        all_variations = []\n",
    "        sift_file = open(siftfile,'r')\n",
    "        for item in sift_file:\n",
    "            item = item.split()\n",
    "            if len(item) > 2:\n",
    "                rs_numbers.append(item[1])\n",
    "                map_variations[item[1]] = item[2]\n",
    "        return rs_numbers, map_variations\n",
    "    \n",
    "    def read_individuals(self, ids, rs_numbers, chrom) :\n",
    "        print('reading in individual mutation files')\n",
    "        mutation_index_array = []\n",
    "        total_mutations={}  \n",
    "        total_mutations_list =[]    \n",
    "        for name in ids :\n",
    "            filename = './' + chrom + 'n/' + chrom + '.' + name\n",
    "            f = open(filename, 'r')\n",
    "            text = f.read()\n",
    "            f.close()\n",
    "            text = text.split()\n",
    "            sifted_mutations = list(set(rs_numbers).intersection(text))\n",
    "            mutation_index_array.append(sifted_mutations)\n",
    "            total_mutations[name]= len(sifted_mutations)\n",
    "            total_mutations_list.append(len(sifted_mutations))\n",
    "        print ('mutation index array for %s : %s' % ( ids[0], mutation_index_array[0]))\n",
    "        print ('total_len_mutations for %s : %s' % ( ids[0], total_mutations[ids[0]]))\n",
    "        print('total_mutations_list is %s ' % total_mutations_list)\n",
    "        return mutation_index_array, total_mutations, total_mutations_list    \n",
    "   \n",
    "    def read_pairs_overlap(self, indpairsfile) :\n",
    "        print('reading in individual crossover mutations')\n",
    "        pairs_overlap = np.loadtxt(indpairsfile, unpack=True)\n",
    "        pairs_overlap = np.transpose(pairs_overlap)\n",
    "        return pairs_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results :\n",
    "    def group_individuals(self, total_mutations_list, n_runs):\n",
    "        print('histograms mutations_individuals groups by 26')\n",
    "        n_group = 26\n",
    "        random_mutations_list= []\n",
    "        for run in range(n_runs):\n",
    "            random_mutations_list.append(sample(total_mutations_list, n_group))\n",
    "        return random_mutations_list\n",
    "\n",
    "    def pair_individuals(self, mutation_index_array, n_runs) :\n",
    "        print('cross matching mutations in individuals')\n",
    "        n_p = len(mutation_index_array)\n",
    "        n_pairs = int(round(n_p/2))\n",
    "        list_p = np.linspace(0, n_p - 1, n_p).astype(int)\n",
    "        pairs_overlap = np.zeros((n_runs, n_pairs))\n",
    "        for run in range(n_runs) :\n",
    "            randomized_list = sample(list(list_p) , n_p)\n",
    "            for pq in range(n_pairs) :\n",
    "                array1 = mutation_index_array[randomized_list[2*pq]]\n",
    "                array2 = mutation_index_array[randomized_list[2*pq]]\n",
    "                pair_array = set(array1) & set(array2)\n",
    "                pairs_overlap[run][pq] = len(pair_array)\n",
    "        return pairs_overlap\n",
    "\n",
    "    def total_pair_individuals (self, mutation_index_array) :\n",
    "        print('cross matching mutations total individuals')\n",
    "        n_p = len(mutation_index_array)\n",
    "        total_pairs_overlap = np.zeros((n_p, n_p))\n",
    "        simetric_overlap = np.zeros((n_p, n_p))\n",
    "        for run in range(n_p):\n",
    "                        array1 = mutation_index_array[run]\n",
    "                        start = run +1\n",
    "                        for pq in range(start, n_p) :\n",
    "                                array2 = mutation_index_array[pq]\n",
    "                                pairs_array = set(array1) & set(array2)\n",
    "                                total_pairs_overlap[run][pq]=len(pairs_array)\n",
    "                                simetric_overlap[run][pq] = len(pairs_array)\n",
    "                                simetric_overlap[pq][run]= len(pairs_array)\n",
    "        return total_pairs_overlap , simetric_overlap\n",
    "\n",
    "    def half_pair_individuals(self, mutation_index_array) :\n",
    "        print('cross matching mutations in individuals - half with half')\n",
    "        n_p = len(mutation_index_array)\n",
    "        n_pairs = int(round(n_p/2))\n",
    "        pairs_overlap = np.zeros((n_pairs, n_pairs))\n",
    "        for run in range(n_pairs):\n",
    "            array1 = mutation_index_array[run]\n",
    "            index =0\n",
    "            for pq in range(n_pairs+1, n_p):\n",
    "                array2 = mutation_index_array[pq]\n",
    "                pairs_array = set(array1) & set(array2)\n",
    "                pairs_overlap[run][index]=len(pairs_array)\n",
    "        return pairs_overlap\n",
    "\n",
    "    def gene_pairs(self, mutation_index_array) :\n",
    "        print('cross matching pairs of variations')\n",
    "        n_p = len(mutation_index_array)\n",
    "        gene_pair_list = {}\n",
    "        for pp in range(n_p) :  \n",
    "            pairs = itertools.combinations(mutation_index_array[pp], 2)\n",
    "            for pair in pairs :\n",
    "                key = str(pair)\n",
    "                if key not in gene_pair_list : gene_pair_list[key] = 1\n",
    "                else : gene_pair_list[key] += 1\n",
    "        return gene_pair_list\n",
    "    \n",
    "    def overlap_ind(self, ids, mutation_index_array, n_runs, n_indiv):\n",
    "        n_p = len(mutation_index_array)\n",
    "        print('calculating the number overlapings mutations between %s individuals selected randomly' % n_p)\n",
    "        list_p = np.linspace(0, n_p - 1, n_p).astype(int)\n",
    "        mutation_overlap = []\n",
    "        random_indiv = []\n",
    "        for run in range(n_runs) :\n",
    "            randomized_list = sample(list(list_p), n_p)\n",
    "            result = Counter()\n",
    "            r_ids=[]\n",
    "            for pq in range(n_indiv):\n",
    "                if 2*pq >= len(randomized_list):\n",
    "                    break\n",
    "                b_multiset = collections.Counter(mutation_index_array[randomized_list[2*pq]])\n",
    "                print('time, inidividual: %s' % ids[randomized_list[2*pq]])\n",
    "                r_ids.append(ids[randomized_list[2*pq]])\n",
    "                result = result + b_multiset\n",
    "            random_indiv.append(r_ids)\n",
    "            mutation_overlap.append(result)\n",
    "        return mutation_overlap, random_indiv\n",
    "    \n",
    "    def histogram_overlap(self, mutation_overlap, n_runs):\n",
    "        print('calculating the frequency/historgram of overlapings mutations')\n",
    "        histogram_overlap= []\n",
    "        for run in range(n_runs):\n",
    "            final_counts = [count for item, count in mutation_overlap[run].items()]\n",
    "            histogram_overlap.append(collections.Counter(final_counts))\n",
    "        return histogram_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotData :        \n",
    "    def individual_overlap(self, POP, c, pairs_overlap, outputFile) :\n",
    "        print('plotting cross matched number of individuals:%s '% len(pairs_overlap))\n",
    "        pairs_overlap = np.array(pairs_overlap)     \n",
    "        min_p = np.min(pairs_overlap)\n",
    "        max_p = np.max(pairs_overlap)\n",
    "        nbins = int(max_p) + 1\n",
    "        n_runs = len(pairs_overlap)\n",
    "        nbins = int(np.max(pairs_overlap))\n",
    "        bin_centres = np.linspace(0, nbins, nbins)\n",
    "        bin_edges = np.linspace(-0.5, nbins + 0.5, nbins + 1)\n",
    "        fig = plt.figure(frameon=False, figsize=(10, 9))\n",
    "        ax = fig.add_subplot(111)\n",
    "        hists = []\n",
    "        max_h = 0\n",
    "        for run in range(n_runs) :\n",
    "            h, edges = np.histogram(pairs_overlap[run], bins = bin_edges)\n",
    "            ax.plot(bin_centres, h, alpha = 0.5)\n",
    "            if len(h) > 0:\n",
    "                max_h = max(max_h, max(h))\n",
    "        plt.xlabel('Number of overlapping gene mutations', fontsize = 24)\n",
    "        plt.ylabel(r'frequency', fontsize = 28)\n",
    "        text1 = 'population ' + POP + '\\n' +\\\n",
    "            'chromosome ' + str(c) + '\\n' + \\\n",
    "            'SIFT < ' + str(SIFT) + '\\n' + \\\n",
    "            str(n_runs) + ' runs'\n",
    "        plt.text(.95, .95, text1, fontsize = 24, \n",
    "            verticalalignment='top', horizontalalignment='right',\n",
    "            transform = ax.transAxes)\n",
    "        plt.savefig(outputFile)  \n",
    "        plt.close()\n",
    "\n",
    "    def total_colormap_overlap(self, POP, total_pairs_overlap, outputFile):\n",
    "        print('plotting colormap number of individuals: %s' % len(total_pairs_overlap))\n",
    "        fig = plt.figure()\n",
    "        cmap = mpl.colors.ListedColormap(['blue','black','red', 'green', 'pink'])\n",
    "        img = pyplot.imshow(total_pairs_overlap,interpolation='nearest', cmap = cmap, origin='lower')\n",
    "        pyplot.colorbar(img,cmap=cmap)\n",
    "        plt.savefig(outputFile)  \n",
    "        plt.close()\n",
    "    \n",
    "    def plot_histogram_overlap(self, POP, histogram_overlap, outputFile, n_runs):\n",
    "        print('ploting Histogram mutation overlap to %s' % outputFile)\n",
    "        for run in range(n_runs):\n",
    "            output = outputFile + str(run) + '.png'\n",
    "            final_counts = [count for item, count in histogram_overlap[run].items()]\n",
    "            N = len( final_counts )\n",
    "            x = range( N )\n",
    "            width = 1/1.5\n",
    "            bar1=plt.bar( x, final_counts, width, color=\"grey\" )\n",
    "            plt.ylabel( 'Mutations' )\n",
    "            plt.xlabel('Individuals')\n",
    "            plt.xticks( np.arange( 1,N+1 ) )\n",
    "            plt.savefig(output)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WriteData :\n",
    "    def write_pair_individuals(self, indpairsfile, pairs_overlap) : \n",
    "        print('writing pairs overlapping mutations to %s' % indpairsfile)\n",
    "        np.savetxt(indpairsfile, pairs_overlap, fmt = '%i')\n",
    "    \n",
    "    def write_gene_pairs(self, genepairsfile, gene_pair_list) :\n",
    "        print('writing gene pair list to %s'% genepairsfile)\n",
    "        f = open(genepairsfile, 'w')\n",
    "        for key, count in gene_pair_list.items() :\n",
    "            f.write(key + '\\t' + str(count) + '\\n')\n",
    "        f.close()\n",
    "    \n",
    "    def write_total_indiv(self, total_mutations_filename, total_mutations) :\n",
    "        print('writing total mutations list per individual to %s' % total_mutations_filename)\n",
    "        f = open(total_mutations_filename, 'w')\n",
    "        for key, count in total_mutations.items() :\n",
    "            f.write(key + '\\t' + str(count) + '\\n')\n",
    "        f.close()\n",
    "\n",
    "    def write_random_indiv(self, randomindiv_file, random_indiv, n_runs) :\n",
    "        for run in range(n_runs):\n",
    "            randomfile = randomindiv_file + str(run) + '.txt'\n",
    "            f = open(randomfile, 'w')\n",
    "            print('writing Random individuals to %s' % randomfile)\n",
    "            f.write('Individuals \\n')\n",
    "            for item in random_indiv[run]:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "            f.close()\n",
    "        \n",
    "    def write_random_mutations_list(self, random_mutations_filename, random_mutations_list, n_runs) :\n",
    "        print('writing a list of 26 random individuals with the number mutations per indiv %s' % random_mutations_filename)\n",
    "        for run in range(n_runs):\n",
    "            filename= random_mutations_filename +'_run_' + str(run) + '.txt'\n",
    "            f = open(filename, 'w')\n",
    "            f.writelines([\"%s\\n\" % item  for item in random_mutations_list[run]])\n",
    "    \n",
    "    def write_mutation_index_array(self, mutation_index_array_file, mutation_index_array):\n",
    "        print('writing mutation array  to %s' % mutation_index_array_file)\n",
    "        f=open(mutation_index_array_file,\"w\")\n",
    "        for item in mutation_index_array:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "        f.close()\n",
    "\n",
    "    def write_map_variations(self, map_variations_file, map_variations) :\n",
    "        print('writing map_variations to %s' % map_variations_file)\n",
    "        f = open(map_variations_file, 'w')\n",
    "        for key, count in map_variations.items() :\n",
    "            f.write(key + '\\t' + str(count) + '\\n')\n",
    "        f.close()\n",
    "        \n",
    "    def write_histogram_overlap(self, histogram_overlapfile, histogram_overlap, n_runs, n_indiv) :\n",
    "        print('writing Frequency historgram of mutations overlapping to %s' % histogram_overlapfile)\n",
    "        for run in range(n_runs):\n",
    "            overlapfile = histogram_overlapfile + str(run) + '.txt'\n",
    "            f = open(overlapfile, 'w')\n",
    "            f.write('Number Individuals - Number Mutations  \\n')\n",
    "            for i in range(1,n_indiv+1):\n",
    "                if i in histogram_overlap[run]:\n",
    "                    f.write(str(i) + '-' + str(histogram_overlap[run][i]) + '\\n')\n",
    "                else:\n",
    "                    f.write(str(i) + '-' + str(0) + '\\n')\n",
    "            f.close()\n",
    "            \n",
    "    def write_mutation_overlap(self, mutation_overlapfile, mutation_overlap, n_runs) :\n",
    "        print('writing Mutations overlapping to %s' % mutation_overlapfile)\n",
    "        for run in range(n_runs):\n",
    "            overlapfile = mutation_overlapfile + str(run) + '.txt'\n",
    "            f = open(overlapfile, 'w')\n",
    "            f.write('Mutation Index- Number Overlapings \\n')\n",
    "            for key, count in mutation_overlap[run].items() :\n",
    "                f.write(key + '-' + str(count) + '\\n')\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task measures the overlap in mutations (also called SNPs variants) among pairs of individuals by population and by chromosome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "workflow": {
     "step": {
      "in": [
       {
        "type": "file",
        "valueFrom": "merged"
       },
       {
        "type": "file",
        "valueFrom": "populations"
       },
       {
        "type": "file",
        "valueFrom": "sift"
       },
       {
        "type": "file",
        "valueFrom": "columns"
       }
      ],
      "out": [
       {
        "name": "output_file",
        "type": "file",
        "value": "*.tar.gz"
       },
       {
        "type": "file",
        "valueFrom": "plot_dir"
       }
      ],
      "scatter": {
       "items": [
        "populations",
        {
         "items": [
          "chromosomes",
          "merged",
          "sift"
         ],
         "method": "dotproduct"
        }
       ],
       "method": "cartesian"
      }
     },
     "target": {
      "model": "helm-1000-genome",
      "service": "1000-genome"
     }
    }
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "n_runs = 1\n",
    "outdata_dir = './output_no_sift/'\n",
    "plot_dir = './plots_no_sift/'\n",
    "OutputFormat = '.png'\n",
    "\n",
    "if not os.path.exists(outdata_dir):\n",
    "    os.makedirs(outdata_dir)\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)\n",
    "\n",
    "for i, c in enumerate(chromosomes):\n",
    "    \n",
    "    tar = tarfile.open(merged[i])\n",
    "    tar.extractall(path='./chr' + str(c) + 'n')\n",
    "    tar.close()\n",
    "    \n",
    "    for pop in populations:\n",
    "        font = {'family':'serif', 'size':14}\n",
    "        plt.rc('font', **font)\n",
    "\n",
    "        rd = ReadData()\n",
    "        res = Results()\n",
    "        wr = WriteData()\n",
    "        pd = PlotData()\n",
    "        \n",
    "        POP = os.path.basename(pop)\n",
    "        half_indpairsfile = outdata_dir + 'individual_half_pairs_overlap_chr' + str(c) + '_s' + \\\n",
    "            str(SIFT) + '_' + POP + '.txt'\n",
    "        total_indpairsfile = outdata_dir + 'total_individual_pairs_overlap_chr' + str(c) + '_s' + \\\n",
    "            str(SIFT) + '_' + POP + '.txt'\n",
    "        genepairsfile = outdata_dir + 'gene_pairs_count_chr' + str(c) + '_s' + \\\n",
    "            str(SIFT) + '_' + POP + '.txt'\n",
    "        random_indpairsfile = outdata_dir + '100_individual_overlap_chr' + str(c) + '_s' + \\\n",
    "            str(SIFT) + '_' + POP + '.txt'\n",
    "\n",
    "        colormap = plot_dir + 'colormap_distribution_c' + str(c) + '_s' + \\\n",
    "                str(SIFT) + '_' + POP + OutputFormat\n",
    "        half_overlap = plot_dir + 'half_distribution_c' + str(c) + '_s' + \\\n",
    "                str(SIFT) + '_' + POP + OutputFormat\n",
    "        total_overlap = plot_dir + 'total_distribution_c' + str(c) + '_s' + \\\n",
    "                str(SIFT) + '_' + POP + OutputFormat\n",
    "        random_overlap = plot_dir + '100_distribution_c' + str(c) + '_s' + \\\n",
    "                str(SIFT) + '_' + POP + OutputFormat\n",
    "\n",
    "        total_mutations_filename = outdata_dir + 'total_mutations_individual' + str(c) + '_s' + \\\n",
    "            str(SIFT) + '_' + POP + '.txt'\n",
    "        random_mutations_filename = outdata_dir + 'random_mutations_individual' + str(c) + '_s' + \\\n",
    "            str(SIFT) + '_' + POP \n",
    "\n",
    "        mutation_index_array_file = outdata_dir + 'mutation_index_array' + str(c) + '_s' + \\\n",
    "            str(SIFT) + '_' + POP + '.txt'\n",
    "\n",
    "        map_variations_file = outdata_dir + 'map_variations' + str(c) + '_s' + \\\n",
    "            str(SIFT) + '_' + POP + '.txt'\n",
    "\n",
    "        ids = rd.read_names(pop, columns)\n",
    "        n_pairs = len(ids)/2\n",
    "\n",
    "\n",
    "        rs_numbers, map_variations = rd.read_rs_numbers(sift[i])\n",
    "        mutation_index_array, total_mutations, total_mutations_list = rd.read_individuals(ids, rs_numbers, 'chr' + str(c))\n",
    "        wr.write_total_indiv(total_mutations_filename, total_mutations)\n",
    "        wr.write_map_variations(map_variations_file, map_variations)\n",
    "\n",
    "        #cross-correlations mutations overlapping\n",
    "        half_pairs_overlap = res.half_pair_individuals(mutation_index_array)\n",
    "        total_pairs_overlap, simetric_overlap = res.total_pair_individuals(mutation_index_array)\n",
    "        random_pairs_overlap = res.pair_individuals(mutation_index_array, n_runs)\n",
    "\n",
    "        wr.write_mutation_index_array(mutation_index_array_file, mutation_index_array)\n",
    "        wr.write_pair_individuals(half_indpairsfile, half_pairs_overlap)\n",
    "        wr.write_pair_individuals(total_indpairsfile, total_pairs_overlap)\n",
    "        wr.write_pair_individuals(random_indpairsfile, random_pairs_overlap)\n",
    "\n",
    "        pd.individual_overlap(POP, c, half_pairs_overlap, half_overlap)\n",
    "        pd.individual_overlap(POP, c, simetric_overlap, total_overlap)\n",
    "        pd.individual_overlap(POP, c, random_pairs_overlap, random_overlap)\n",
    "        pd.total_colormap_overlap(POP, total_pairs_overlap, colormap)\n",
    "\n",
    "        #list of frecuency of mutations in 26 individuals\n",
    "        random_mutations_list=res.group_individuals(total_mutations_list, n_runs)\n",
    "        wr.write_random_mutations_list(random_mutations_filename, random_mutations_list, n_runs)\n",
    "\n",
    "        # gen overlapping\n",
    "        gene_pair_list = res.gene_pairs(mutation_index_array)\n",
    "        wr.write_gene_pairs(genepairsfile, gene_pair_list)\n",
    "\n",
    "        # gen final output\n",
    "        tar = tarfile.open('chr%s-%s.tar.gz' % (c, POP), 'w:gz')\n",
    "        tar.add(outdata_dir)\n",
    "        tar.add(plot_dir)\n",
    "        tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tasks measures the frequency of overlapping in mutations by selecting a number of random individuals, and selecting all SNPs variants without taking into account their SIFT scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "workflow": {
     "step": {
      "in": [
       {
        "type": "file",
        "valueFrom": "merged"
       },
       {
        "type": "file",
        "valueFrom": "populations"
       },
       {
        "type": "file",
        "valueFrom": "sift"
       },
       {
        "type": "file",
        "valueFrom": "columns"
       }
      ],
      "out": [
       {
        "name": "output_file",
        "type": "file",
        "value": "*.tar.gz"
       },
       {
        "type": "file",
        "valueFrom": "plot_dir"
       }
      ],
      "scatter": {
       "items": [
        "populations",
        {
         "items": [
          "chromosomes",
          "merged",
          "sift"
         ],
         "method": "dotproduct"
        }
       ],
       "method": "cartesian"
      }
     },
     "target": {
      "model": "helm-1000-genome",
      "service": "1000-genome"
     }
    }
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "n_runs = 1000\n",
    "n_indiv= 52\n",
    "outdata_dir = './output_no_sift/'\n",
    "plot_dir = './plots_no_sift/'\n",
    "\n",
    "OutputFormat = '.png'\n",
    "\n",
    "if not os.path.exists(outdata_dir):\n",
    "    os.makedirs(outdata_dir)\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)\n",
    "    \n",
    "for i, c in enumerate(chromosomes):\n",
    "    \n",
    "    tar = tarfile.open(merged[i])\n",
    "    tar.extractall(path='./chr' + str(c) + 'n')\n",
    "    tar.close()\n",
    "    \n",
    "    for pop in populations:\n",
    "        font = {'family':'serif', 'size':14}\n",
    "        plt.rc('font', **font)\n",
    "\n",
    "        rd = ReadData()\n",
    "        res = Results()\n",
    "        wr = WriteData()\n",
    "        pd = PlotData()\n",
    "        \n",
    "        POP = os.path.basename(pop)\n",
    "        histogram_overlapfile = outdata_dir + 'Histogram_mutation_overlap_chr' + str(c) + '_s' + \\\n",
    "            str(SIFT) + '_' + POP + '_'\n",
    "        mutation_overlapfile = outdata_dir + 'Mutation_overlap_chr' + str(c) + '_s' + \\\n",
    "            str(SIFT) + '_' + POP + '_'\n",
    "        mutation_index_array_file = outdata_dir + 'mutation_index_array' + str(c) + '_s' + \\\n",
    "            str(SIFT) + '_' + POP + '.txt'\n",
    "        histogram_overlap_plot = plot_dir + 'Frequency_mutations' + str(c) + '_s' + \\\n",
    "            str(SIFT) + '_' + POP \n",
    "        map_variations_file = outdata_dir + 'map_variations' + str(c) + '_s' + \\\n",
    "            str(SIFT) + '_' + POP + '.txt'\n",
    "        randomindiv_file = outdata_dir + 'random_indiv' + str(c) + '_s' + \\\n",
    "            str(SIFT) + '_' + POP + '_'\n",
    "\n",
    "        ids = rd.read_names(pop, columns)\n",
    "        n_pairs = len(ids)/2\n",
    "\n",
    "        rs_numbers, map_variations = rd.read_rs_numbers(sift[i])\n",
    "        mutation_index_array, _, _ = rd.read_individuals(ids, rs_numbers, 'chr' + str(c))\n",
    "        print(mutation_index_array)\n",
    "\n",
    "        wr.write_map_variations(map_variations_file, map_variations)\n",
    "        wr.write_mutation_index_array(mutation_index_array_file, mutation_index_array)\n",
    "\n",
    "        mutation_overlap, random_indiv= res.overlap_ind(ids, mutation_index_array, n_runs, n_indiv)\n",
    "        histogram_overlap= res.histogram_overlap(mutation_overlap, n_runs)\n",
    "\n",
    "        wr.write_mutation_overlap(mutation_overlapfile, mutation_overlap, n_runs)\n",
    "        wr.write_histogram_overlap(histogram_overlapfile, histogram_overlap, n_runs, n_indiv)\n",
    "        wr.write_random_indiv(randomindiv_file, random_indiv, n_runs)\n",
    "\n",
    "        pd.plot_histogram_overlap(POP, histogram_overlap, histogram_overlap_plot, n_runs)\n",
    "\n",
    "        # gen final output\n",
    "        tar = tarfile.open('chr%s-%s-freq.tar.gz' % (c, POP), 'w:gz')\n",
    "        tar.add(outdata_dir)\n",
    "        tar.add(plot_dir)\n",
    "        tar.close()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Jupyter Workflow",
   "language": "python",
   "name": "jupyter-workflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "workflow": {
   "interpreter": "ipython",
   "models": {
    "helm-1000-genome": {
     "config": {
      "chart": "environment/k8s/1000-genome",
      "inCluster": true,
      "releaseName": "1000-genome"
     },
     "type": "helm"
    }
   },
   "version": "v1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
