{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Car-Parrinello simulation on Quantum ESPRESSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to assess the *Jupyter-workflow* capabilities to enable interactive simulations of realistic, large-scale systems, we implement a Notebook describing a multi-step simulation workflow in Quantum ESPRESSO.\n",
    "\n",
    "In particular, the analyzed workflow implements a Car-Parrinello simulation of 32 Water Molecules, with the aim to sample the water at different temperatures using a Nose-hover thermostat together with a reference microcanonical trajectory.\n",
    "\n",
    "The workflow is composed of six steps, which were executed on top of the PBS-managed *davinci-1* facility, the HPC centre of the Leonard S.p.A. company.\n",
    "\n",
    "This time we did not use a Singularity container, but ran the steps directly on bare metal to fully exploit compile-time optimisations of a Quantum ESPRESSO executable compiled with Intel OneAPI. Nevertheless, we packed both the executable (named `cp-oneapi.x`) and all the input files inside the `INPDIR` directory.\n",
    "\n",
    "In order to replicate the experiment in a fully-optimised execution environment, you need to compile the Quantum ESPRESSO `cp` executable directly on your facility. The [node-details.txt file](https://raw.githubusercontent.com/alpha-unito/jupyter-workflow/master/examples/quantum-espresso/node-details.txt) provides some information on the libraries used to compile Quantum ESPRESSO. Then, you need to set the correct credentials in the Notebook metadata (e.g. `username` and `sshKey`) and, if necessary, modify the PBS script template at `environment/pbs_espresso`.\n",
    "\n",
    "Moreover, please note that both the input directory and the output directory should preserve their names (i.e., `INPDIR` and `OUTDIR`, respectively) because their paths are directly encoded inside Quantum ESPRESSO input files. Data dependencies are propagated between subsequent steps through the `OUTDIR` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step performs an electronic minimization, in order to bring the electronic density in the ground state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "stime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false,
    "workflow": {
     "step": {
      "in": [
       {
        "name": "input_dir",
        "type": "file",
        "value": "INPDIR"
       }
      ],
      "out": [
       {
        "name": "output_dir",
        "type": "file",
        "value": "OUTDIR"
       }
      ],
      "workdir": "/path/to/shared/workdir"
     },
     "target": {
      "model": "qe-docker"
     }
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$input_dir\"\n",
    "cp -r $1 .\n",
    "mkdir OUTDIR\n",
    "mpirun -np 16 -f $PBS_NODEFILE sh -c \"./INPDIR/cp-oneapi.x < ./INPDIR/h2o.in.00 > ./OUTDIR/h2o.out.00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.341166734695435\n"
     ]
    }
   ],
   "source": [
    "print(time.time() - stime)\n",
    "stime = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step performs a randomization of the ionic degree of freedom, followed by a new electronic minimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "workflow": {
     "step": {
      "in": [
       {
        "name": "input_dir",
        "type": "file",
        "valueFrom": "input_dir"
       },
       {
        "name": "output_dir",
        "type": "file",
        "valueFrom": "output_dir"
       }
      ],
      "out": [
       {
        "name": "output_dir",
        "type": "file",
        "value": "OUTDIR"
       }
      ],
      "workdir": "/path/to/shared/workdir"
     },
     "target": {
      "model": "qe-docker"
     }
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$input_dir\" \"$output_dir\"\n",
    "cp -r $1 $2 .\n",
    "mpirun -np 16 -f $PBS_NODEFILE sh -c \"./INPDIR/cp-oneapi.x < ./INPDIR/h2o.in.01 > ./OUTDIR/h2o.out.01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.089718103408813\n"
     ]
    }
   ],
   "source": [
    "print(time.time() - stime)\n",
    "stime = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third step performs one thousand steps of a combined ionic and electronic microcanonical simulation to integrate the Car-Parrinello lagrangian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "workflow": {
     "step": {
      "in": [
       {
        "name": "input_dir",
        "type": "file",
        "valueFrom": "input_dir"
       },
       {
        "name": "output_dir",
        "type": "file",
        "valueFrom": "output_dir"
       }
      ],
      "out": [
       {
        "name": "output_dir",
        "type": "file",
        "value": "OUTDIR"
       }
      ],
      "workdir": "/path/to/shared/workdir"
     },
     "target": {
      "model": "qe-docker"
     }
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$input_dir\" \"$output_dir\"\n",
    "cp -r $1 $2 .\n",
    "mpirun -np 16 -f $PBS_NODEFILE sh -c \"./INPDIR/cp-oneapi.x < ./INPDIR/h2o.in.02 > ./OUTDIR/h2o.out.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174.44248843193054\n"
     ]
    }
   ],
   "source": [
    "print(time.time() - stime)\n",
    "stime = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the workflow forks in three different directions, which can all be executed in parallel. In particular, they perform:\n",
    "\n",
    "1. A continuation of the microcanonical simulation of the third step, used as a reference\n",
    "2. A continuation of the third step using a thermostat set at 350 Kelvin degrees\n",
    "3. A continuation of the third step using a thermostat set at 400 Kelvin degrees\n",
    "\n",
    "This configuration can be easily represented in *Jupyter-workflow* as a `scatter` operation on the input configuration files. The three resulting jobs are then concurrently scheduled on the remote HPC facility, while the *Jupyter-workflow* driver waits for their termination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = ['b0', 'b1', 'b2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "workflow": {
     "step": {
      "in": [
       {
        "name": "input_list",
        "type": "name",
        "valueFrom": "input_list"
       },
       {
        "name": "input_dir",
        "type": "file",
        "valueFrom": "input_dir"
       },
       {
        "name": "output_dir",
        "type": "file",
        "valueFrom": "output_dir"
       }
      ],
      "scatter": {
       "items": [
        "input_list"
       ]
      },
      "workdir": "/path/to/shared/workdir"
     },
     "target": {
      "model": "qe-docker"
     }
    }
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$input_list\" \"$input_dir\" \"$output_dir\"\n",
    "INPUTS=($(echo $1 | tr -d '[],'))\n",
    "cp -r $2 $3 .\n",
    "for INPUTVAR in ${INPUTS[*]}; do\n",
    "  INPUT=$(echo $INPUTVAR | tr -d \\')\n",
    "  mkdir OUTDIR.$INPUT\n",
    "  cp -r -P OUTDIR/*  OUTDIR.$INPUT\n",
    "  mpirun -np 16 -f $PBS_NODEFILE sh -c \"./INPDIR/cp-oneapi.x < ./INPDIR/h2o.in.03.${INPUT} > ./OUTDIR.$INPUT/h2o.out.03.${INPUT}\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188.18521285057068\n"
     ]
    }
   ],
   "source": [
    "print(time.time() - stime)\n",
    "stime = time.time()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Jupyter Workflow",
   "language": "python",
   "name": "jupyter-workflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "workflow": {
   "interpreter": "/path/to/ipython/interpreter",
   "models": {
    "qe-docker": {
     "config": {
      "file": "environment/pbs_espresso",
      "hostname": "10.122.0.6",
      "maxConcurrentJobs": 3,
      "sshKey": "/path/to/ssh/key",
      "username": "ssh-username"
     },
     "type": "pbs"
    }
   },
   "version": "v1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
